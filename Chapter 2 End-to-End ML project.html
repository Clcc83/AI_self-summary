<html>
<head>
  <title>Chapter 2 End-to-End ML project</title>
  <basefont face="微软雅黑" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="YXBJ Windows/607057 (zh-CN, DDL); Windows/10.0.0 (Win64); EDAMVersion=V2;"/>
  <style>
    body, td {
      font-family: 微软雅黑;
      font-size: 10pt;
    }
  </style>
</head>
<body>
<a name="709"/>
<h1>Chapter 2 End-to-End ML project</h1>

<div><span><h1 style="text-align:center;">Chapter 2 End-to-End ML project</h1><div><span style="background-color: #fff199;"><span style="font-weight: bold;">SCIKIT-LEARN DESIGN   P64</span></span></div><h2>Working with Real Data</h2><p style="text-align:start;"><span style="font-weight: 600;">数据来源：</span></p><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div>California Housing Prices dataset from the StatLib repository</div></div><p style="text-align:start;">加州人口普查数据包括：</p><ul><li><div>人口</div></li><li><div>收入中位数</div></li><li><div>加州每个街区的房价中位数（这里的街区是美国人口普查局公布样本数据的最小地理单位）</div></li></ul><p style="text-align:start;">目标：从这些数据中学习模型，来预测房价</p><img src="Chapter 2 End-to-End ML project_files/Image.jpg" type="image/jpeg" data-filename="Image.jpg" style="--en-uploadstate:uploaded;" width="616px"/><h2>Frame the Problem</h2><h3><span style="font-size: 12pt;">了解实际目标：</span></h3><p style="text-align:start;">实际目标将决定如何构建问题，选择什么算法，将使用什么性能度量来评估模型，以及花费多少精力来对它进行调整。这个问题的实际目标是<span style="font-weight: 600;">通过预测房价来决定投资</span>。</p><p style="text-align:start;"><br/></p><p style="text-align:start;"><span style="font-weight: 600;">观察现有的解决方案：</span>现有的方案可以提供一定的参考和不同的视角。该问题现有的解决方案是专家团人工估计房价，这种解决方案低效而耗时。</p><p style="text-align:start;"><br/></p><p style="text-align:start;">这是一个多元回归问题，因为要利用多个特征进行预测。这也是一个单变量回归问题，因为我们预测的是单个值。没有连续的数据流进入系统，不需要特别快速调整数据来应对变化，而且数据足够小，可以放入内存，<b>所以普通的批量学习就可以</b>。</p><p style="text-align:start;"><br/></p><h2>Select a Performance Measure</h2><img src="Chapter 2 End-to-End ML project_files/HI~[{TSI7Z%KW7LYR5I)[)E.png" type="image/png" data-filename="HI~[{TSI7Z%KW7LYR5I)[)E.png" style="--en-uploadstate:uploaded;"/><div><span style="font-size: 16pt;"><span style="color: #FF0000;">要点注意</span></span></div><div><span style="font-size: 14pt;"><span style="background-color: #fff199;"><span style="font-weight: bold;">1.NOTATIONS （标记）——P40</span></span></span></div><div><span style="font-size: 14pt;"><span style="background-color: #fff199;"><span style="font-weight: bold;">2.创建测试集</span></span></span></div><ul><li><div>在进一步查看数据之前，您需要创建一个测试集，将其放在一边，并且永远不要查看它。</div></li><li><div>random_state参数允许设置<span style="font-weight: 600;">随机生成器种子</span>。随机数种子控制每次划分训练集和测试集的模式，其取值不变时划分得到的结果一模一样，其值改变时，划分得到的结果不同。若不设置此参数，则函数会自动选择一种随机模式，得到的结果也就不同。</div></li><li><div><span style="color: #FF0000;"><b>随机抽样：最简便split_train_test()函数；分层抽样：StratifiedShuffleSplit 类</b></span></div></li></ul><div><span style="font-size: 14pt;"><span style="background-color: #fff199;"><span style="font-weight: bold;">3.数据探索</span></span></span></div><ul><li><div>可视化</div></li></ul><img src="Chapter 2 End-to-End ML project_files/(44HB03802VFQHEM5AJP%5F.png" type="image/png" data-filename="(44HB03802VFQHEM5AJP%5F.png" style="--en-uploadstate:uploaded;" width="588px"/><ul><li><div>相关性</div></li></ul><div>（1）corr()函数</div><div>（2）Another way to check for correlation between attributes is to use the pandas <span style="background-color: #fff199;">scatter_matrix() </span>function, which plots every numerical attribute against every other numerical attribute.</div><ul><li><div>组合探索</div></li></ul><div>有一些特征单独拿出来并不是很有用，比如总房间数和总卧室数，当它们以“平均每个房子的房间数”，“平均每个房间的卧室数”，“平均每个房子的人口数”的组合特征形式出现时会更有用。<b>计算出组合特征后再来观察相关系数矩阵</b>（此时有12个特征）会发现新的特征与房价之间具有更强的相关性。</div><div>eg：housing[&quot;population_per_household&quot;]=housing[&quot;population&quot;]/housing[&quot;households&quot;]</div><div><br/></div><div>我们之前所做的<span style="font-weight: 600;">可视化、相关性分析和组合特征</span>工作只是为了对我们的数据有一个更清晰的认识和洞察，是一个简单的准备工作。接下来我们要正式对数据进行预处理。</div><div><br/></div><div><span style="font-size: 16pt;"><span style="background-color: #fff199;"><span style="font-weight: bold;">4.数据预处理</span></span> </span>  </div><div>       出于提高复用性和可重用性的目的，同时也为了尝试不同组合的效果，我们需要写一些函数来为我们的机器学习算法准备数据。</div><ul><li><p style="text-align:start;">首先把用来预测的<span style="font-weight: 600;">特征</span>和<span style="font-weight: 600;">标签</span>进行分离：</p></li></ul><p style="text-align:start;">housing = strat_train_set.drop(&quot;median_house_value&quot;, axis=1)  housing_labels = strat_train_set[&quot;median_house_value&quot;].copy() </p><ul><li><p style="text-align:start;"><span style="font-weight: 600;">缺省数据</span></p></li></ul><p style="text-align:start;">原数据中<i>total_bedrooms</i>属性存在缺失的情况，处理缺失数据的方法：</p><div>（1）去掉缺失数据的样本</div><div>（2）去掉整个特征</div><div>（3）将缺省值设置为某个值(0、均值、中位数等)</div><p style="text-align:start;">使用DataFrame的dropna()、drop()和fillna()方法可以轻松地完成这些任务:</p><p style="text-align:start;"><span style="color: #FF0000;">Scikit-Learn提供了一个方便的类来处理缺失的值：<span style="font-weight: 600;">SimpleImputer</span>。首先，创建一个SimpleImputer实例，指定想要用属性的中位数来替换每个属性缺失的值：</span></p><p style="text-align:start;"><span style="color: #FF0000;">from sklearn.impute import SimpleImputer  </span></p><p style="text-align:start;"><span style="color: #FF0000;">imputer = SimpleImputer(strategy=&quot;median&quot;) </span></p><p style="text-align:start;">由于中位数只能通过数值属性计算，因此需要创建一个没有文本属性<span style="font-weight: 400;"><i>ocean_proximity</i></span>的数据副本：</p><p style="text-align:start;">housing_num = housing.drop(&quot;ocean_proximity&quot;, axis=1)</p><p style="text-align:start;"><span style="background-color: #fff199;">imputer.fit(housing_num) </span>imputer简单地计算了每个属性的中位数，并将结果存储在其<span style="font-weight: 400;"><i>statistics_instance</i></span>变量中</p><p style="text-align:start;"><br/></p><ul><li><p style="text-align:start;"><span style="font-weight: 600;">文本属性</span></p></li></ul><p style="text-align:start;">（1）绝大多数机器学习算法喜欢处理数值类型的数据，所以我们需要把文本属性转化为数值属性，可以使用Scikit-Learn的<span style="background-color: #fff199;">OrdinalEncoder类</span>做这个工作。</p><p style="text-align:start;">from sklearn.preprocessing import OrdinalEncoder</p><p>ordinal_encoder = OrdinalEncoder()</p><p>housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)      转化为0,1,2,3,4（实质是定序变量）</p><p><br/></p><p>（2）但是这个方法有一个问题，计算文本属性的距离有时候可能不够准确，比如把两个相近的属性反而设置成了较远的距离，解决方法是<span style="font-weight: 600;">one-hot编码</span>：当类别为“&lt;1H OCEAN”时，一个属性等于1(否则为0)，当类别为“INLAND”时，另一个属性等于1(否则为0)，依此类推。之所以称为one-hot编码，是因为向量中只有一个属性等于1(hot)，而其他属性将等于0(cold)。</p><p style="text-align:start;">Scikit-Learn提供了一个<span style="background-color: #fff199;">OneHotEncoder类，用于将分类值转换为一个one-hot向量：</span></p><p style="text-align:start;"><span style="color: #FF0000;">from sklearn.preprocessing import OneHotEncoder</span></p><p><span style="color: #FF0000;">cat_encoder = OneHotEncoder()</span></p><p><span style="color: #FF0000;">housing_cat_1hot = cat_encoder.fit_transform(housing_cat)      </span></p><p>得到的housing_cat_1hot是一个Scipy<b>稀疏矩阵，而不是Numpy数组（可toarray()转化为数组）</b>。之所以不用Numpy数组是因为ont-hot向量组成的矩阵会有大量的0，使用大量的内存来存储零是非常浪费的，故只存非0值信息。另外，我们还可以使用categories_ 来获取分类列表。</p><div><br/></div><ul><li><div><span style="font-weight: 600;">自定义转换器</span></div></li></ul><div>sklearn已经提供了很多转换器，如果想自定义转换器，可以<b>定义一个新的类并且实现其fit()【要一个数据集作为参数，对我们随后将应用的特定转换函数执行所需的计算】,transform()【fit()之后，返回的是经过转换的数据集】,fit_transform()三个方法</b>。（三者联系如下）</div><div><a href="https://blog.csdn.net/SanyHo/article/details/105334174" rev="en_rl_none">(125条消息) sklearn | fit()、transform()、fit_transform() 三者联系与区别_Sany 何灿的博客-CSDN博客</a></div><p style="text-align:start;"><span style="color: #FF0000;">添加<span style="font-weight: 600;"><i>TransformerMixin</i></span>作为基类，会直接得到fit_transform()方法；                  基类（父类）</span></p><p style="text-align:start;"><span style="color: #FF0000;">添加<span style="font-weight: 600;"><i>BaseEstimator</i></span>作为基类，可以获得两个自动调整超参数的方法：get_params()和set_params()</span></p><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div>超参= 在开始机器学习之前，就人为设置好的参数。如KNN中的k</div><div>模型参数=通过训练得到的参数数据。</div><div>通常情况下，需要对超参数进行优化，给学习机选择一组最优超参数，以提高学习的性能和效果</div><div><abbr lang="lineHeight" style="line-height: 2.0;background-color:;color:;">from sklearn.base import BaseEstimator, TransformerMixin</abbr></div></div><p><abbr lang="lineHeight" style="line-height: 2.0;background-color:;color:;"># column index</abbr></p><p><abbr lang="lineHeight" style="line-height: 2.0;background-color:;color:;">rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6</abbr></p><p><abbr lang="lineHeight" style="line-height: 2.0;background-color:;color:;">class CombinedAttributesAdder(BaseEstimator, TransformerMixin):          ##继承</abbr></p><p><abbr lang="lineHeight" style="line-height: 2.0;background-color:;color:;">    def<span style="color: #FF0000;"> __init__</span>(self, <span style="background-color: #fff199;">add_bedrooms_per_room = True</span>): # no *args or **kargs</abbr></p><p><abbr lang="lineHeight" style="line-height: 2.0;background-color:;color:;">        self.add_bedrooms_per_room = add_bedrooms_per_room</abbr></p><p><abbr lang="lineHeight" style="line-height: 2.0;background-color:;color:;">    def <span style="color: #FF0000;">fit</span>(self, X, y=None):</abbr></p><p><abbr lang="lineHeight" style="line-height: 2.0;background-color:;color:;">        return self  # 不用做其他事情</abbr></p><p><abbr lang="lineHeight" style="line-height: 2.0;background-color:;color:;">    def <span style="color: #FF0000;">transform</span>(self, X):</abbr></p><p><abbr lang="lineHeight" style="line-height: 2.0;background-color:;color:;">        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]</abbr></p><p><abbr lang="lineHeight" style="line-height: 2.0;background-color:;color:;">        population_per_household = X[:, population_ix] / X[:, households_ix]</abbr></p><p><abbr lang="lineHeight" style="line-height: 2.0;background-color:;color:;">        if self.add_bedrooms_per_room:</abbr></p><p><abbr lang="lineHeight" style="line-height: 2.0;background-color:;color:;">            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]</abbr></p><p><abbr lang="lineHeight" style="line-height: 2.0;background-color:;color:;">            return np.c_[X, rooms_per_household, population_per_household,</abbr></p><p><abbr lang="lineHeight" style="line-height: 2.0;background-color:;color:;">                         bedrooms_per_room]</abbr></p><p><abbr lang="lineHeight" style="line-height: 2.0;background-color:;color:;">        else:</abbr></p><p><abbr lang="lineHeight" style="line-height: 2.0;background-color:;color:;">            return np.c_[X, rooms_per_household, population_per_household]</abbr></p><p><abbr lang="lineHeight" style="line-height: 2.0;background-color:;color:;">attr_adder = CombinedAttributesAdder(<span style="background-color: #fff199;">add_bedrooms_per_room=False</span>)</abbr></p><p><abbr lang="lineHeight" style="line-height: 2.0;background-color:;color:;">housing_extra_attribs = attr_adder.<span style="background-color: #fff199;">transform</span>(housing.values)</abbr></p><div>在上面的代码中，转换器有一个超参数<span style="font-weight: 400;"><i>add_bedrooms_per_room</i></span>，它被默认设置为True。这个超参数可以帮我们发现添加这个转换属性是否对我们的机器学习算法有帮助。更一般地，对于我们不确定是否对算法有用的属性，我们都可以添加超参数去设置任何可能的数据组合，设置的组合越多，我们就越有可能找到一个有用的组合。</div><p><br/></p><ul><li><div><span style="font-weight: 600;">特征放缩（Feature Scaling）</span></div></li></ul><div>方式一：先对整个数据集数据标准化后再划分训练集、测试集     F</div><div><span style="background-color: #fff199;">方式二：先对训练级标准化再将规则用于测试集     T</span></div><p style="text-align:start;">当输入的数值属性具有非常不同的尺度时，ML算法往往表现不佳，所以需要进行特征的放缩，两种常用的方法：<span style="font-weight: 600;">最小最大放缩（min-max scaling）</span>和<span style="font-weight: 600;">标准化（standardization）</span></p><p style="text-align:start;">（1）最小最大放缩：数据值被放缩到0-1的区间，具体来说，减去最小值然后除以最大值减去最小值。</p><img src="Chapter 2 End-to-End ML project_files/7WI]6G`7U}W(Y0AD9RHUNQE.png" type="image/png" data-filename="7WI]6G`7U}W(Y0AD9RHUNQE.png" style="--en-uploadstate:uploaded;"/><p>（2）标准化：首先减去平均值，然后除以标准差，经过处理的数据的均值为0，标准差为1。与最小-最大放缩不同的是，标准化不会将值绑定到特定的范围。</p><img src="Chapter 2 End-to-End ML project_files/B0PT]61H(OGSSD~B}6}LTG2.png" type="image/png" data-filename="B0PT]61H(OGSSD~B}6}LTG2.png" style="--en-uploadstate:uploaded;"/><ul><li><div><span style="font-weight: 600;">管道</span></div></li></ul><div>数据处理需要按照正确的步骤来进行，Scikit-Learn提供了管道类来帮助处理这样的转换序列：</div><div>from sklearn.pipeline import Pipeline </div><p>from sklearn.preprocessing import StandardScaler </p><p>num_pipeline = Pipeline([ </p><p>    ('imputer', SimpleImputer(strategy=&quot;median&quot;)), </p><p>    ('attribs_adder', CombinedAttributesAdder()), </p><p>    ('std_scaler', StandardScaler()), ]) </p><p>housing_num_tr = num_pipeline.fit_transform(housing_num)</p><p><br/></p><p style="text-align:start;">管道的构造函数接受<span style="background-color: #fff199;">定义步骤序列的（name，estimator）对的列表</span>，除了最后一个estimator【estimator,transformer,predictors】以外，其他的esitimator都必须是转换器。</p><div>流水线的输入为一连串的数据处理步骤，其中最后一步必须是估计器（Estimator），可理解成分类器。前几步是转换器（Transformer）。输入的数据集经过转换器的处理后，输出的结果作为下一步的输入。最后，用位于流水线最后一步的估计器对数据进行分类.</div><div> </div><ul><li><div><span style="font-weight: 600;">ColumnTransformer</span></div></li></ul><div>目前为止我们讨论了对于<span style="font-weight: 600;">数值</span>属性和<span style="font-weight: 600;">分类文本</span>属性的转换器，如果有一个转换器可<span style="background-color: #fff199;">以处理所有属性会更加方便</span>，Scikit-Learn为此引入了ColumnTransformer：</div><div>from sklearn.compose import ColumnTransformer </div><p><span style="background-color: #fff199;">num_attribs = list(housing_num) </span></p><p><span style="background-color: #fff199;">cat_attribs = [&quot;ocean_proximity&quot;] </span></p><p>full_pipeline = ColumnTransformer([ </p><p>    (&quot;num&quot;, num_pipeline, num_attribs), </p><p>    (&quot;cat&quot;, OneHotEncoder(), cat_attribs), ]) </p><p>housing_prepared = full_pipeline.fit_transform(housing)</p><p>首先导入ColumnTransformer类，然后获得<span style="font-weight: 600;">数值</span>列名列表和<span style="font-weight: 600;">分类</span>列名列表，<span style="font-weight: 600;">再构造一个ColumnTransformer</span>。构造函数需要一个元组列表，其中每个元组包含一个名称，一个转换器和一个列名列表。在本例中，我们的数值列使用前面定义的num_pipeline转换器，分类列使用OneHotEncoder转换器。最后，我们将这个ColumnTransformer应用于住房数据。</p><p><br/></p><h3 style="text-align:start;"><span style="background-color: #fff199;"><span style="font-weight: 600;">5、Select and Train a Model</span></span></h3><div>详见P72      在输入了解（调整）模型时，先多尝试一下不同模型</div><h3 style="text-align:start;"><span style="background-color: #fff199;"><span style="font-weight: 600;">6、Fine-Tune Your Model</span></span></h3><div>对我们模型进行一些现微调的工作。</div><p style="text-align:start;"><span style="font-weight: 600;">一、Grid Search</span></p><p style="text-align:start;">一种笨办法是手动修改超参数，直到找到超参数值的最佳组合，这显然是低效的。我们可以使用Scikit-Learn的<span style="font-weight: 600;">GridSearchCV</span>帮助我们搜索，我们只需要告诉它使用哪些超参数进行实验，以及希望得到的值，它将使用交叉验证来评估超参数值的所有可能组合。</p><p style="text-align:start;">下面的代码为RandomForestRegressor搜索超参数值的最佳组合:</p><p style="text-align:start;">（网格搜索将探索12 + 6 = 18个RandomForestRegressor超参数值的组合，并将对每个模型进行5次训练，一共90轮训练）</p><p style="text-align:start;">from sklearn.model_selection import GridSearchCV</p><p><span style="background-color: #fff199;">param_grid = [</span></p><p><span style="background-color: #fff199;">    # try 12 (3×4) combinations of hyperparameters</span></p><p><span style="background-color: #fff199;">   </span><span style="color: #FF0000;"><span style="background-color: #fff199;"> {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},</span></span></p><p><span style="background-color: #fff199;">    # then try 6 (2×3) combinations with bootstrap set as False</span></p><p><span style="background-color: #fff199;">   </span><span style="color: #003CB3;"><span style="background-color: #fff199;"> {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},</span></span></p><p><span style="background-color: #fff199;">  ]</span></p><p>forest_reg = RandomForestRegressor(<span style="background-color: #fff199;">random_state</span>=42)</p><p># train across 5 folds, that's a total of (12+6)*5=90 rounds of training </p><p>grid_search = GridSearchCV(forest_reg, param_grid, cv=5,</p><p>                           scoring='neg_mean_squared_error',</p><p>                           return_train_score=True)</p><p>grid_search.fit(housing_prepared, housing_labels)</p><img src="Chapter 2 End-to-End ML project_files/Image [1].jpg" type="image/jpeg" data-filename="Image.jpg" style="--en-uploadstate:uploaded;"/><p>得到结果如下：（注意迭代结果中最佳的n_estimators超参数是30，而我们尝试的最大值也是30，这启发我们可以尝试选取比30更大的n_estimators值）</p><p><br/></p><div>注：<span style="font-weight: 600;">GridSearchCV默认通过交叉验证找到最优参数后在全部训练集里重新训练模型；可以将一些数据准备步骤（异常值处理，特征选择 ）视为超参数</span></div><p><br/></p><div>random_state可以用于很多函数，我比较熟悉的是用于以下三个地方：</div><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><p><b><span style="font-weight: 400;">1、训练集测试集的划分</span></b></p><p><b><span style="font-weight: 400;">2、构建决策树           </span></b><span style="background-color: #ffffff;"><span style="font-weight: 400;">其取值不变时，用相同的训练集建树得到的结果一模一样，对测试集的预测结果也是一样的</span></span></p><p><b><span style="font-weight: 400;">3、构建随机森林</span></b></p></div><div><span style="font-weight: 600;">二、Randomized Search</span></div><p style="text-align:start;">当超参数搜索空间很大难以穷举时，通常更可取的方法是使用<span style="font-weight: 600;">RandomizedSearchCV</span>。它不会尝试所有可能的组合，而是通过在每次迭代中为每个超参数选择一个随机值来计算给定数量的随机组合。这种方法的好处是<span style="font-weight: 600;">随机探索，同时更好地控制分配给超参数搜索的计算预算。</span></p><p style="text-align:start;"><span style="font-weight: 600;">三、 Ensemble Methods</span></p><p style="text-align:start;">调整系统的另一种方法是尝试<span style="background-color: #fff199;">组合性能最好的模型</span>。团队（或“集合”）的表现往往比单个模型更好，尤其是当单个模型可能会犯各种不同类型的错误时。典型集成学习的例子就是决策树和随机森林。</p><p style="text-align:start;"><span style="font-weight: 600;">四、Analyze the Best Models and Their Errors</span></p><p style="text-align:start;">通过检视模型我们往往可以得到一些不错的视角。比如feature_importances可以表示表示每个属性对于准确预测的相对重要性。通过这些信息，可能会有利于我们尝试删除一些不太有用的特性。</p><p style="text-align:start;">feature_importances = grid_search.best_estimator_.feature_importances_ </p><p>&gt;&gt;&gt; feature_importances </p><p>#输出：array([7.33442355e-02, 6.29090705e-02, 4.11437985e-02, 1.46726854e-02, </p><p>#1.41064835e-02, 1.48742809e-02, 1.42575993e-02, 3.66158981e-01, </p><p>#5.64191792e-02, 1.08792957e-01, 5.33510773e-02, 1.03114883e-02,1.64780994e-01, </p><p>#6.02803867e-05, 1.96041560e-03, 2.85647464e-03])</p><img src="Chapter 2 End-to-End ML project_files/`VDHVGZIQ1W3TEBO06Z(FEQ.png" type="image/png" data-filename="`VDHVGZIQ1W3TEBO06Z(FEQ.png" style="--en-uploadstate:uploaded;" width="577px"/><h3 style="text-align:start;"><span style="background-color: #fff199;"><span style="font-weight: 600;">7、 Your System on the Test Set</span></span></h3><div><b>final_model = grid_search.best_estimator_ </b></div><p><span style="color: #007A05;">X_test = strat_test_set.drop(&quot;median_house_value&quot;, axis=1) </span></p><p><span style="color: #007A05;">y_test = strat_test_set[&quot;median_house_value&quot;].copy() </span></p><p><span style="color: #007A05;">X_test_prepared = full_pipeline.transform(X_test)      #同样要预处理</span></p><p>final_predictions = final_model.predict(X_test_prepared) </p><p>final_mse = mean_squared_error(y_test, final_predictions) </p><p>final_rmse = np.sqrt(final_mse) # =&gt; evaluates to 47,730.2</p><div><br/></div><div><span style="font-size: 12pt;"><span style="background-color: #fff199;">注意：如果您做了大量的超参数调优，那么性能通常会比使用交叉验证测量的性能稍微差一些</span>（因为您的系统最终进行了微调，以便在验证数据上表现良好，而在未知数据集上可能不会表现得太好）。在本例中并非如此，但当这种情况发生时，您必须抵制调整超参数的诱惑，使数字在测试集上看起来不错；这些改进不太可能推广到新的数据中。</span></div><div><br/></div><h3 style="text-align:start;"><span style="font-weight: 600;">8、Launch, Monitor, and Maintain Your System</span></h3><p style="text-align:start;">我们的模型训练完毕了！也通过了测试，接下来我们可以将模型<span style="font-weight: 600;">部署到生产环境</span>中。一种方法是<span style="font-weight: 600;">保存经过训练的Scikit-Learn模型</span>（例如，使用joblib)，包括完整的预处理和预测管道，然后在生产环境中加载这个经过训练的模型，并通过调用它的<span style="font-weight: 600;">predict()</span>方法来进行预测。</p><p style="text-align:start;">例如，该模型可能会在网站中使用：用户将键入关于新区域的一些数据，然后单击Estimate Price按钮。这将<span style="font-weight: 600;">向web服务器发送一个包含数据的查询</span>，web服务器将把数据转发给您的web应用程序，最后，代码将简单地调用模型的<span style="font-weight: 600;">predict()</span>方法（我们需要在服务器启动时加载模型，而不是每次使用模型时都加载一遍模型）。</p><p style="text-align:start;">另外，还可以将模型<span style="font-weight: 600;">封装在专用的web服务</span>中，相关的web应用程序可以通过REST API23查询该服务。这使我们可以更容易地将模型升级到新版本，而不会中断主应用程序。它还简化了可伸缩性，我们可以根据需要启动任意数量的web服务，并通过这些web服务平衡来自web应用程序的请求。</p><img src="Chapter 2 End-to-End ML project_files/Image.webp" type="image/webp" data-filename="Image.webp" style="--en-uploadstate:uploaded;"/><p style="text-align:start;">另外一种流行的策略是把<span style="font-weight: 600;">模型部署在云端</span>，例如Google Cloud AI Platform。只需使用joblib保存您的模型并将其上传到谷歌云存储(GCS)，然后前往谷歌云AI平台并创建一个新的模型版本，并将其指向GCS文件。这为我们提供了一个简单的web服务，它将能够处理负载平衡和扩展。它接受包含输入数据的JSON请求(例如，一个地区的数据)，并返回包含预测的JSON响应。然后，可以在具体的网站中使用此web服务。</p><p style="text-align:start;">当然，部署并不是任务的完成，我们还需要<span style="font-weight: 600;">编写监视代码</span>来定期检查系统的实时性能，并在性能下降时触发警报，定义在<span style="font-weight: 600;">出现故障时应该做什么，以及如何准备故障</span>。同时，随着时间的推移和数据不断发展，会出现数据腐烂的现象，我们需要<span style="font-weight: 600;">定期更新数据集和重新训练模型</span>，实时<span style="font-weight: 600;">维护</span>我们的系统。 如果需要，还可以尽可能让整个过程自动化。</p><p style="text-align:start;">最后，确保对创建的每个模型都进行备份，并准备好流程和工具，以便快速回滚到以前的模型，以防新模型由于某种原因出现严重故障。</p><p style="text-align:start;"><br/></p><h3 style="text-align:start;">总结</h3><p style="text-align:start;">这一章通过美国房价的预测的例子，让我们对一个<span style="font-weight: 600;">完整的机器学习项目</span>有清晰直观的了解。正如我们所见，大多数的工作需要在数据准备中进行：熟悉数据、建立数据可视化、设置数据预处理管道以及模型的训练。接下来我们需要在验证集上评估模型，进行模型选择，对模型进行微调，测试模型。最后我们还要将模型投入生产和装载，不能忘记维护和监视系统，定期更新数据集。</p><div><br/></div><p><br/></p></span>
</div></body></html> 