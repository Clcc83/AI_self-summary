<html>
<head>
  <title>Chapter 4.2 Training Models</title>
  <basefont face="微软雅黑" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="YXBJ Windows/607057 (zh-CN, DDL); Windows/10.0.0 (Win64); EDAMVersion=V2;"/>
  <style>
    body, td {
      font-family: 微软雅黑;
      font-size: 10pt;
    }
  </style>
</head>
<body>
<a name="909"/>
<h1>Chapter 4.2 Training Models</h1>

<div><span><h1 style="text-align:center;">Chapter 4.2 Training Models</h1><h2>二、Polynomial Regression - 多项式（多次方）回归 （⚠️ 多次方回归这个名称是我自己发明的）</h2><div>将<span style="background-color: #fff199;">每个特征的幂作为新特征添加进来</span>，然后在<b>这个扩展的特征集</b>上训<span style="background-color: #fff199;">练一个线性模型</span>。（事物是复杂的，线性回归是单纯的，可贵的是用单纯的线性回归就可以解决多项式回归，只需要把特性值（features) 多次方化，然后用线性回归直接fit（训练）即可。）</div><div><br/></div><div>下面是演示如何用线性回归来拟合多次方的情况：</div><img src="Chapter 4.2 Training Models_files/DRIYD[$R2Q8@OM$XQV~Y%17.png" type="image/png" data-filename="DRIYD[$R2Q8@OM$XQV~Y%17.png" style="--en-uploadstate:uploaded;"/><div><br/></div><div>note：请注意，当<span style="background-color: #fff199;">存在多个特征时</span>，多项式回归能够找到特征之间的关系（这是一个普通的线性回归模型所不能做到的）。这是由于多项式特征也将所有特征的组合添加到给定的程度。</div><img src="Chapter 4.2 Training Models_files/Image.png" type="image/png" data-filename="Image.png" style="--en-uploadstate:uploaded;"/><div>要小心特征爆炸</div><div><br/></div><div>现在问题来了，上面的例子我们事先知道了X和Y的关系是二次方的关系（我们已经知道答案了），所以拿二次方化的X去做拟合，当然可以得到很好的结果，但是现实的情况下面，我们<b>并不知道X和Y是几次方的关系，那该怎么办呢？</b></div><div><b>提高degree的值（也就是提高方次数</b>）可以使得结果更好的拟合训练集合，但是带来的问题就是<span style="background-color: #fff199;">over-fitting</span>: 对于validation集合的预测结果非常差。</div><img src="Chapter 4.2 Training Models_files/3YP7~JZJOEP9(XXWYGNEFOA.png" type="image/png" data-filename="3YP7~JZJOEP9(XXWYGNEFOA.png" style="--en-uploadstate:uploaded;"/><img src="https://pic1.zhimg.com/80/v2-f6c25563286457a038fc9f063690f048_720w.webp"></img><div>当degree=300的时候过拟合非常明显，degree=1的时候欠拟合非常明显。</div><p style="text-align:start;"><span style="background-color: #fff199;">我们如何可以知道一个模型是过拟合还是欠拟合呢？</span>（通常简单的模型容易欠拟合，复杂的模型容易过拟合 - 如上图所示）</p><p style="text-align:start;">我们在第二章学习过一个<b>Cross-Validation的方法</b>。</p><ul><li><div>当一个模型对训练集的预测的结果很好，但是cross-validation结果很差就是明显的过拟合</div></li><li><div>当训练集和cross-validation的结果都很差的时候，就是欠拟合</div></li></ul><div><span style="font-size: 18pt;"><span style="font-weight: bold;">Learning Curves</span></span></div><p style="text-align:start;"><b>还有一种方法，本章进行了介绍 -</b><span style="background-color: #fff199;"><b>Learning Curve</b></span>，<span style="color: #FF0000;"><b>方法是每次只用一部分的X进行训练，然后看一下模型在训练集和Validation集的表现，然后再逐步增加X的数量，看看结果</b></span>。</p><img src="Chapter 4.2 Training Models_files/Image [1].png" type="image/png" data-filename="Image.png" style="--en-uploadstate:uploaded;"/><div>定义画图函数，degree=1</div><img src="Chapter 4.2 Training Models_files/%{UYDZ_M79TLU2HQOWM34K2.png" type="image/png" data-filename="%{UYDZ_M79TLU2HQOWM34K2.png" style="--en-uploadstate:uploaded;" width="506px"/><div>解释：红色线是预测training集合时候的表现，蓝色线条是预测Val集合时候的表现，当用比较少的X训练的时候当然线性回归得到的表现好，但是Val集合的表现差，随着越来越多的X被加入训练，模型在training集合的error很快达到平衡，并且再多的输入也无法降低error，Val一开始很高，很快下降到2左右，也是再也无法下降了。</div><img src="Chapter 4.2 Training Models_files/H[M5GYG)[GUG%78](M7FS6O.png" type="image/png" data-filename="H[M5GYG)[GUG%78](M7FS6O.png" style="--en-uploadstate:uploaded;" width="470px"/><div>from sklearn.pipeline import Pipeline</div><p>polynomial_regression = <span style="background-color: #fff199;"><b>Pipeline</b></span>([</p><p>    (&quot;poly_features&quot;, PolynomialFeatures(degree=20, include_bias=False),),</p><p>    (&quot;std_scale&quot;, std_scaler),</p><p>    (&quot;lin_reg&quot;, LinearRegression()),</p><p>])</p><p><b>plot_learning_curves</b>(polynomial_regression, X, y)     </p><p>这张图和线性回归产生的图有下面这些不同：</p><ol><li><div><span style="color: #FF0000;">训练集合的error很小</span></div></li><li><div><span style="color: #FF0000;">Val的error和train的error中间的间距很大</span></div></li></ol><p style="text-align:start;">以上两点同时存在的时候，我们可以确定在degree=20的时候，我们确实出现了<span style="background-color: #fff199;">过拟合现象</span>。</p><p style="text-align:start;"><br/></p><div style="text-align:start;"><span style="background-color: #fff199;">正则化可以解决过拟合问题</span></div><h2><b><span style="font-weight: bold;">三、Regularized Linear Models</span></b></h2><div><b>首先，先理解Bias和Variance的区别</b></div><div><a href="https://zhuanlan.zhihu.com/p/45213397" rev="en_rl_none">机器学习中的Bias和Variance - 知乎 (zhihu.com)</a></div><div><a href="https://zhuanlan.zhihu.com/p/38853908" rev="en_rl_none">偏差（Bias）与方差（Variance） - 知乎 (zhihu.com)</a></div><h3>概念定义</h3><ul><li><div><b><span style="font-weight: bold;">偏差导致的误差</span></b>：偏差引起的误差被视为模型的预期（或平均）预测与我们试图预测的正确值之间的差异。当然，您只有一个模型，因此谈论预期或平均预测值可能看起来有点奇怪。但是，<b>假设您可以多次重复整个模型构建过程：每次收集新数据并运行新分析创建新模型时。由于基础数据集的随机性，生成的模型将具有一系列预测。</b><span style="background-color: #fff199;"><b>偏差衡量这些模型的预测通常与正确值相差多远</b></span><b>。</b></div></li><li><div>方<b><span style="font-weight: bold;">差导致的误差：方</span></b>差引起的误差被视为<span style="background-color: #fff199;">给定数据点</span>的模型预测的变异性。同样，<span style="background-color: #fff199;">假设您可以多次重复整个模型构建过程。方差是给定点的预测在模型的不同实现之间变化的程度。（预测值的方差）Variance代表这算法的鲁棒性。</span></div></li></ul><ul><li><div><span style="font-weight: 600;">Bias</span>是用<span style="font-weight: 600;">所有可能的训练数据集</span>训练出的<span style="font-weight: 600;">所有模型</span>的输出的<span style="font-weight: 600;">平均值</span>与<span style="font-weight: 600;">真实模型</span>的输出值之间的差异。——欠 </div></li><li><p style="text-align:start;"><span style="font-weight: 600;">Variance</span>是<span style="font-weight: 600;">不同的训练数据集训练出的模型</span>输出值之间的差异。——过拟合</p></li><li><p style="text-align:start;"><span style="font-weight: 600;">噪声</span>的存在是学习算法所无法解决的问题，数据的质量决定了学习的上限。假设在数据已经给定的情况下，此时上限已定，我们要做的就是尽可能的接近这个上限。</p></li></ul><img src="Chapter 4.2 Training Models_files/0GK2DARUFW7I~IRKDJWTKB6.png" type="image/png" data-filename="0GK2DARUFW7I~IRKDJWTKB6.png" style="--en-uploadstate:uploaded;" width="406px"/><div>我们可以使用靶心图创建偏差和方差的图形可视化。想象一下，<span style="background-color: #fff199;">目标的中心是一个完美预测正确值的模型</span>。当我们远离靶心时，我们的预测变得越来越糟糕。想象一下，我们可以<b>重复整个模型构建过程，以在目标上获得许多单独的命中</b>。鉴于我们收集的训练数据中的机会可变性，<u>每次命中都代表我们模型的单独实现。有时我们会得到训练数据的良好分布，因此我们的预测非常好，并且我们接近靶心，而有时我们的训练数据可能充满异常值或非标准值，从而导致较差的预测。这些不同的实现导致目标上的命中分散。</u></div><img src="Chapter 4.2 Training Models_files/IUMX]DA}4D%5ZGOE`40DCIE.png" type="image/png" data-filename="IUMX]DA}4D%5ZGOE`40DCIE.png" style="--en-uploadstate:uploaded;" width="489.36495636871456px"/><img src="Chapter 4.2 Training Models_files/D~)E2@%W8B78)53`KTH64HH.png" type="image/png" data-filename="D~)E2@%W8B78)53`KTH64HH.png" style="--en-uploadstate:uploaded;" width="466px"/><div>一般来说，偏差与方差是有冲突的，这称为<span style="font-weight: 600;">偏差-方差窘境（bias-variance dilemma）</span>。下图给出了一个示意图。给定学习任务，假定我们能控制学习算法的训练程度，则<b>在训练不足时，学习器的拟合能力不够强，训练数据的扰动不足以使学习器产生显著变化，此时偏差主导了泛化错误率</b>；<span style="color: #FF0000;">随着训练程度的加深，学习器的拟合能力逐渐增强，训练数据发生的扰动渐渐能被学习器学到，方差逐渐主导了泛化错误率</span>；在训练程度充足后，学习器的拟合能力已经非常强，训练数据发生的轻微扰动都会导致学习器发生显著变化，若训练数据自身的、非全局的特性被学习器学到了，则将发生过拟合。</div><div><br/></div><div><br/></div><div>好了，那么我们如果解决过拟合的问题呢？减少过拟合的一个好方法是将模型正则化（即约束它）：它的<b>自由度越少，它就越难过拟合数据</b>。正则化多项式模型的一种简单方法是减少多项式度的数目。对于一个线性模型，正则化通常是通过<span style="background-color: #fff199;">约束模型的权重（西格玛）</span>来实现的，有三种方法来处理，<span style="background-color: #fff199;">这三种方法都是在Cost Function的基础上面加上一个惩罚值：</span></div><h2><span style="font-size: 16pt;">1、Ridge Regression</span></h2><div>岭回归（也称为提洪诺夫正则化）</div><img src="Chapter 4.2 Training Models_files/EM){JMWSM%Q$AE@C5UJ6GR6.png" type="image/png" data-filename="EM){JMWSM%Q$AE@C5UJ6GR6.png" style="--en-uploadstate:uploaded;" width="544px"/><p style="text-align:start;">增加了这个惩罚之后，得到的拟合结果会对输入的X不敏感。当a=0的时候，Ridge Regression的cost function和线性回归无区别，但是当我们<span style="background-color: #fff199;">增加a的值的时候，拟合曲线会对输入越来越不敏感</span>，当a非常大的时候，拟合曲线对输入已经无感，所以就变成了一个平行的直线。所以Ridge Regression是通过降低对training集合的 敏感度来达到消除过拟合的目的。</p><div style="--en-blockquote:true;box-sizing: border-box; padding-left: 19px; padding-top: 6px; padding-bottom: 6px; border-left: 3px solid #b4c0cc; background-position: initial initial; background-repeat: initial initial; margin-top: 6px"><div>note：在执行岭回归之前，对数据进行缩放（例如，使用<span style="color: #FF0000;"><b>标准缩放器</b></span>）是很重要的，因为它对输入特征的规模很敏感。这对于大多数正则化的模型都是如此。</div></div><img src="Chapter 4.2 Training Models_files/3RV}DE65J4)J@WQAZBP@~$T.png" type="image/png" data-filename="3RV}DE65J4)J@WQAZBP@~$T.png" style="--en-uploadstate:uploaded;" width="488px"/><img src="Chapter 4.2 Training Models_files/H0ZE[0MQ(BXBU1@@3W_R6DC.png" type="image/png" data-filename="H0ZE[0MQ(BXBU1@@3W_R6DC.png" style="--en-uploadstate:uploaded;" width="532px"/><div>即应用了岭回归</div><div><br/></div><h3>2. Lasso Regression:</h3><div>套索回归</div><div>it uses the ℓ1norm of the weight vector instead of half the square of the ℓ2norm</div><div><span style="background-color: #fff199;">即为权重向量的绝对值，而不是权重向量平方的一半。</span></div><div>Lasso回归的一个重要特征是，它<b>倾向于消除最不重要的特征的权重（即，将它们设为零）</b>。例如，图4-18（α=10-7）中的虚线看起来是二次的，几乎是线性的：对于高阶多项式特征的所有权值都等于零。换句话说，<b>Lasso回归自动执行特征选择，并输出一个稀疏模型（即，具有非零的特征权值很少）</b>。</div><img src="Chapter 4.2 Training Models_files/3NBIV7RNLHC8{C8THB6}M`S.png" type="image/png" data-filename="3NBIV7RNLHC8{C8THB6}M`S.png" style="--en-uploadstate:uploaded;" width="518px"/><div><br/></div><h2>3. Elastic Net</h2><img src="Chapter 4.2 Training Models_files/N(MX2N5W2ZX3WNLI{%]2DPN.png" type="image/png" data-filename="N(MX2N5W2ZX3WNLI{%]2DPN.png" style="--en-uploadstate:uploaded;" width="628.2341479536171px"/><div><span style="background-color: #fff199;">正则化几乎总是可取的，所以通常你应该避免纯线性回归</span>。<b>Ridge是一个很好的默认值，但如果你怀疑只有少数特征是有用的，你应该更喜欢Lasso, or Elastic Net，因为它们倾向于将无用的特征的权重减少到零，我们已经讨论过。一般来说，弹性网比Lasso更可取，因为当特征数量大于训练实例数量或多个特征强相关时，Lasso可能会表现不规律。</b></div><div><br/></div><h3>Early Stopping</h3><div>被Hilton大神称为“美丽免费午餐的方式”</div><div><span style="color: #0056FF;">简单说就是我可以使用一个比较复杂的模型来做训练，复杂模型的特点就是对训练集合的拟合度比较好（Low Bias），但是对Test集合的拟合度较差（High Variance）</span></div><p style="text-align:start;"><b>那么解决方法就是我们在用梯度下降逼近模型结果的时候观察一下Test集合（或者叫做Validation集合）的error，当Validation集合的error随着epoch的增加从逐渐下降到重新升高的时候，我们就停止模型的训练，从而得到最好的θ。（详见jupyter）</b></p><img src="Chapter 4.2 Training Models_files/IMG_20230328_191948.jpg" type="image/jpeg" data-filename="IMG_20230328_191948.jpg" style="--en-uploadstate:uploaded;" width="506.2999954223633px"/><div><br/></div></span>
</div></body></html> 